{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Web Scraping\n",
    "\n",
    "To begin, we will examine the reddit page dealing with Machine Learning.  Our goal is to scrape the basic information for posts.\n",
    "\n",
    "![](images/reddit.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>This is a header</h1>\n",
       "<p class = 'super-paragraph'>This would be a paragraph. <strong>Strong Words</strong> here.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h1>This is a header</h1>\n",
    "<p class = 'super-paragraph'>This would be a paragraph. <strong>Strong Words</strong> here.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_21_Jump_Street_episodes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>List of 21 Jump Street episodes - Wikipedia</title>\\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\\\s)client-nojs(\\\\s|$)/, \"$1client-js$2\" );</script>\\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"List_of_21_Jump_Street_episodes\",\"wgTitle\":\"List of 21 Jump Street episodes\",\"wgCurRevisionId\":844038329,\"wgRevisionId\":844038329,\"wgArticleId\":35403829,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles needing additional references from May 2012\",\"All articles needing additional references\",\"21 Jump Street\",\"Lists of American crime television series episodes\"],\"wgBreakFrames\":false,\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgSeparatorTransfo'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2>Contents</h2>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents\n",
      "Series Overview[edit]\n",
      "Season 1 (1987)[edit]\n",
      "Season 2 (1987-88)[edit]\n",
      "Season 3 (1988-89)[edit]\n",
      "Season 4 (1989-90)[edit]\n",
      "Season 5 (1990-91)[edit]\n",
      "References[edit]\n",
      "Navigation menu\n"
     ]
    }
   ],
   "source": [
    "all_h2s = soup.find_all('h2')\n",
    "\n",
    "for h2 in all_h2s:\n",
    "    print(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><i><a href=\"/wiki/21_Jump_Street\" title=\"21 Jump Street\">21 Jump Street</a></i> is an American <a href=\"/wiki/Police_procedural\" title=\"Police procedural\">police procedural</a> <a class=\"mw-redirect\" href=\"/wiki/Crime_drama\" title=\"Crime drama\">crime drama</a> <a class=\"mw-redirect\" href=\"/wiki/Television_series\" title=\"Television series\">television series</a> that aired on the <a href=\"/wiki/Fox_Broadcasting_Company\" title=\"Fox Broadcasting Company\">Fox Network</a> and in first run syndication from April 12, 1987, to April 27, 1991, with a total of 103 <a href=\"/wiki/Episode\" title=\"Episode\">episodes</a>. The series focuses on a squad of youthful-looking undercover police officers investigating crimes in high schools, colleges, and other teenage venues.<sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup>\n",
       "</p>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table_1 = soup.find('table',{'class':'wikitable plainrowheaders'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"summary\" style=\"text-align:left\">\"Pilot\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"America, What a Town\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"Don't Pet the Teacher\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"My Future's So Bright, I Gotta Wear Shades\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"The Worst Night of Your Life\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"Gotta Finish the Riff\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"Bad Influence\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"Blindsided\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"Next Generation\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"Low and Away\"<br/>\"Running on Ice\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"16 Blown to 35\"</td>,\n",
       " <td class=\"summary\" style=\"text-align:left\">\"Mean Streets and Pastel Houses\"</td>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_1_titles = table_1.find_all('td',{'class':'summary'})\n",
    "\n",
    "season_1_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pilot\"\n",
      "\"America, What a Town\"\n",
      "\"Don't Pet the Teacher\"\n",
      "\"My Future's So Bright, I Gotta Wear Shades\"\n",
      "\"The Worst Night of Your Life\"\n",
      "\"Gotta Finish the Riff\"\n",
      "\"Bad Influence\"\n",
      "\"Blindsided\"\n",
      "\"Next Generation\"\n",
      "\"Low and Away\"\"Running on Ice\"\n",
      "\"16 Blown to 35\"\n",
      "\"Mean Streets and Pastel Houses\"\n"
     ]
    }
   ],
   "source": [
    "for title in season_1_titles:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for i in soup.find_all('a', {'data-click-id': 'body'}):\n",
    "    url_link = 'https://www.reddit.com' + i['href']\n",
    "    links.append(url_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "titles = []\n",
    "bodys = []\n",
    "for i in soup.find_all('a', {'data-click-id': 'body'}):\n",
    "    url_link = 'https://www.reddit.com' + i['href']\n",
    "    links.append(url_link)\n",
    "    response = requests.get(url_link)\n",
    "    soup2 = BeautifulSoup(response.text, 'html.parser')\n",
    "    title = soup2.find('h2')\n",
    "    body = soup2.find_all('p')\n",
    "    titles.append(title)\n",
    "    bodys.append(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'links': links, 'title': titles, 'body': bodys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Exercise\n",
    "\n",
    "Scraping Wikipedia tables and adding information found through links.\n",
    "\n",
    "![](images/wiki_table.png)\n",
    "\n",
    "Problem:\n",
    "\n",
    "1. Create a dataframe that contains the information displayed on the Wikipedia page \"List of 2018 Albums\".\n",
    "2. What is Sub Pop releasing in 2018?\n",
    "3. Did Drake put anything out?\n",
    "4. What label is putting out the most music?  Visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_2018_albums'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('table', {'class':'wikitable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweepy\n",
    "\n",
    "- Sign into Twitter apps (https://apps.twitter.com/)\n",
    "- Create application and retrieve `consumer_key`, `consumer_secret`, `access_token`, and `access_token_secret`.  \n",
    "- Follow example below filling in your info.  For more info, see the Tweepy documentation [here](http://tweepy.readthedocs.io/en/v3.5.0/getting_started.html#introduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'kZFSwW1kezEqG8a1rP79BEbus'\n",
    "consumer_secret = '8vMwEDPji62FqCVmgkqjZ0FtYWJeVhmWOfLXFMlEUFoewKqhhz'\n",
    "access_token = '4922450361-27KxaE3Oy6G3jSbXMtIetPBZiVUIWtgGFj83OyE'\n",
    "access_token_secret = 'u6T9vRox2ozs33uMvjBsGVP5nK1FKBJzbIx2I6kjil2Lf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user('qz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it bad to shop on Amazon? https://t.co/O4cvuvMUWL https://t.co/qXRMeXaGtv\n",
      "Cash is pouring into tech startups from every source https://t.co/CGLQZPNZmY\n",
      "Donald Trump already told us why he‚Äôs shouting at Iran https://t.co/K2pOvo8B60\n",
      "Donald Trump already told us why he‚Äôs shouting at Iran https://t.co/Fw4GF0xvSY\n",
      "American cheese is no longer the most popular cheese in America https://t.co/nA5dP7VhxJ\n",
      "In the race to a $1 trillion valuation, analysts are still betting on Apple over Amazon https://t.co/PgTdINZJob\n",
      "From elephants to eagles: the evolving brands of Nigeria‚Äôs unsuccessful national airlines https://t.co/wBbgV4v3bO\n",
      "Why the world is so excited about electric cars https://t.co/knCcMPwpfF\n",
      "This album documents the lasting impact of Sudan on Africa‚Äôs music scene https://t.co/AuNqzifeUN\n",
      "It‚Äôs not all about advertising at Alphabet anymore https://t.co/Mjv4dmXBIV\n",
      "Africa is now the world‚Äôs epicenter of modern-day slavery https://t.co/4Z2YqoDsUJ\n",
      "It's impossible to lead a totally ethical life‚Äîbut it's fun to try https://t.co/TY7TCOOic4 https://t.co/1sJRnpeiBd\n",
      "Student engineers set a speed record in Elon Musk‚Äôs hyperloop competition https://t.co/rv9Aw2mJmo\n",
      "What happens when you downsize an organization you don‚Äôt understand, New York Daily News edition https://t.co/nsUzToXNRJ\n",
      "This CEO is an example of why you need to be careful on your company‚Äôs laptop https://t.co/ceiYULaqB9\n",
      "If you missed the rogue tweets, we screengrabbed them for you. https://t.co/gLDwnNV7an\n",
      "90‚Äôs metal band Papa Roach made the only good joke about Donald Trump‚Äôs Iran meltdown https://t.co/CgrNOM7m1L\n",
      "RT @thu: Forbes took down that op-ed saying that Amazon should replace local libraries https://t.co/559GZcIayi\n",
      "In Jonathan Gold‚Äôs Los Angeles the least fancy restaurants matter the most https://t.co/g5Izww0AJE\n",
      "90‚Äôs metal band Papa Roach made the only good joke about Donald Trump‚Äôs Iran meltdown https://t.co/vU9F1oL8Mf\n"
     ]
    }
   ],
   "source": [
    "for tweet in user.timeline():\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359396\n"
     ]
    }
   ],
   "source": [
    "print(user.followers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for tweet in user.timeline(count = 200):\n",
    "    tweets.append(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is it bad to shop on Amazon? https://t.co/O4cvuvMUWL https://t.co/qXRMeXaGtv',\n",
       " 'Cash is pouring into tech startups from every source https://t.co/CGLQZPNZmY',\n",
       " 'Donald Trump already told us why he‚Äôs shouting at Iran https://t.co/K2pOvo8B60',\n",
       " 'Donald Trump already told us why he‚Äôs shouting at Iran https://t.co/Fw4GF0xvSY',\n",
       " 'American cheese is no longer the most popular cheese in America https://t.co/nA5dP7VhxJ']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "karen = api.get_user('_karenhao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Wolfe321: A meme for our time. https://t.co/Hq5K5fijfY\n",
      "@jennygzhang i'm reading abe lincoln's biography by goodwin right now and he used to write out the letter he wanted‚Ä¶ https://t.co/4LGty29I70\n",
      "RT @WhenWeAllVote: Your vote is your voice. #WhenWeAllVote, we all do better. Register and volunteer at https://t.co/TgXnKAE7g8. https://t.‚Ä¶\n",
      "@AkshatRathi You're not giving enough credit to the rocket guy https://t.co/oB1iqNxLzp\n",
      "Wow interesting https://t.co/SmtXA3oFxY\n",
      "RT @missanabeem: This is a wonderful opportunity https://t.co/VAOL7GlULF\n",
      "Uncannily similar to my own process. https://t.co/RKpd9wW9PO\n",
      "Being told by the instructor of my machine learning class ‚Äúwell yeah, it‚Äôs all a black box that‚Äôs fine ü§∑üèº‚Äç‚ôÇÔ∏è‚Äù while‚Ä¶ https://t.co/RRjNGel10m\n",
      "@dancow Oh yikes, that Mother Jones interview was done by me‚Äîit didn't occur to me how powerful an identifier a tweet reference could be\n",
      "Does @Refinery29 realize how much hate this will get. https://t.co/asr7x4dvID\n",
      "RT @ChappellTracker: 6 These reviews of the ant emoji by an entomologist¬†\n",
      "https://t.co/hULTXqal4J https://t.co/zI4icywHEa\n",
      "RT @Lin_Manuel: Gmorning! \n",
      "A bit of news‚Äî\n",
      "At YOUR request, we made a book of the Gmornings &amp; Gnights!\n",
      "Illustrations by @jonnysun!\n",
      "Available‚Ä¶\n",
      "These moments are why I still use Twitter https://t.co/WD7qICo3QY\n",
      "@JasonShen Haha that‚Äôs pretty amazing. I guess what happened in Vegas didn‚Äôt stay in Vegas üòè\n",
      "@canonind Yes! Haha whoever founded the first pi reunion is ingenious.\n",
      "@sarutofu For everyone haha\n",
      "Most colleges have 5 year reunions. MIT has pi reunions. They happen 3.14 years after we grauduate. In Vegas. I know.\n",
      "RT @Lin_Manuel: This headline really could have been written during any one of my 38 years alive https://t.co/tBSFZ93ogP\n",
      "TIL there's a python library called fuzzywuzzy ‚ù§Ô∏è https://t.co/nRE3kPTVR1\n",
      "RT @VAMNit: #HBDFridaKahlo, my 1st heroine. ‚ÄúI don't give a shit what the world thinks. I was born a bitch, I was born a painter, I was bor‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "for tweet in karen.timeline():\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "karen.followers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Table\n",
    "\n",
    "![](images/open_table.png)\n",
    "\n",
    "Finding restaurants in New York City. (https://www.opentable.com/new-york-restaurant-listings)  Is there good Indian food in the Upper West Side?  Where?  What are people saying is good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
