{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Assignment\n",
    "\n",
    "The main goal of this assignment is to check in on your ability to access, load, explore, and make predictions using classification models.  For next Wednesday, you are to do the following:\n",
    "\n",
    "1. Locate a dataset on Kaggle, NYC Open Data, UCI Machine Learning Repository, or other resource that contains data that can be addressed through a classification task\n",
    "2. Load and explore the data for missing values and perform a brief EDA\n",
    "3. Frame and state the classification problem\n",
    "4. Split your data into train and test sets\n",
    "4. Implement a `DummyClassifier`, `KNeighborsClassifier`, and `LogisticRegression` model.\n",
    "5. Improve the models by performing a `GridSearchCV` for `n_neighbors` and `C` parameters respectively.  Include a scale transformation in your pipeline for KNN and a `PolynomialFeatures` step in the Logistic model.\n",
    "6. Discuss the outcome of your classifiers using the `classification_report`.  Which did the best?  Do you prefer a recall or a precision oriented model?  Why?\n",
    "\n",
    "**EXTRA**:\n",
    "\n",
    "- Include `SGDClassifier`\n",
    "- Incorporate AUC and ROC curves\n",
    "\n",
    "\n",
    "Note: If you can't find a good dataset, use the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# set chart style\n",
    "sns.set(style='ticks')\n",
    "%matplotlib inline\n",
    "\n",
    "# choose laptop location\n",
    "home = '/Users/karenhao'\n",
    "office = '/users/khao'\n",
    "\n",
    "location = home+'/Google Drive/02 Working/Quartz/Education/GA Data Science/DAT-NYC-6.13'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 0. import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About the data**\n",
    "\n",
    "https://www.kaggle.com/kemical/kickstarter-projects\n",
    "\n",
    "\n",
    "* `ID`: internal kickstarter id\n",
    "* `name`: name of kickstarter project\n",
    "* `category`: category\n",
    "* `main_category`: category of campaign\n",
    "* `currency`: currency used to support\n",
    "* `deadline`: deadline for crowdfunding\n",
    "* `goal`: fundraising goal in local currency\n",
    "* `launched`: date launched\n",
    "* `pledged`: amount of money pledged in local currency\n",
    "* `state`: state of campaign (successful, failed, other)\n",
    "* `backers`: number of backers\n",
    "* `country`: country pledged from\n",
    "* `usd pledged`: amount of money pledged in usd\n",
    "* `usd_pledged_real`: amount of money pledged in usd\n",
    "* `usd_goal_real`: fundraising goal in usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(location+'/data')\n",
    "kickstarter = pd.read_csv('ks-projects-201801.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kickstarter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1. check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kickstarter.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `name` and `usd pledged` are the only columns with null values. We don't care about `name`, but we might care about `usd pledged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kickstarter[kickstarter['usd pledged'].isnull()].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From examinining rows where `usd pledged` is null, it seems ok to use `usd_pledged_real` instead, which accurately converts `pledged` to usd.\n",
    "\n",
    "### step 2. understanding existing variables\n",
    "\n",
    "Now we continue to explore each of the columns. We start by checking the value counts for some of the key columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kickstarter.category.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kickstarter.main_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kickstarter.currency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kickstarter.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the distributions of different variables based on the `state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='state',y='usd_goal_real',data=kickstarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the outliers in `usd_goal_real`, it's too hard to tell what is actually going on in the above boxplot. Let's get rid of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution\n",
    "kickstarter.usd_goal_real.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "ks = kickstarter.copy()\n",
    "ks = ks[ks.usd_goal_real<ks.usd_goal_real.quantile(.95)]\n",
    "\n",
    "ks.usd_goal_real.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try visualizing `usd_goal_real` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='state',y='usd_goal_real',data=ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='state',y='backers',data=ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, there are too many outliers in `backers`. Let's do the same thing as we did with `usd_goal_real`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers again\n",
    "ks = ks[ks.backers<ks.backers.quantile(.95)]\n",
    "sns.boxplot(x='state',y='backers',data=ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above boxplot, `backers` seems like a great way to classify the success of a campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "sns.countplot(x='main_category',hue='state',data=ks,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `main_category`, on the other hand, doesn't seem like a great way to classify success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3. create new variables\n",
    "\n",
    "Let's calculate a new variable from `launched` and `deadline` that represents the duration of the campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to dates\n",
    "ks['launched'] = pd.to_datetime(ks.launched).dt.date\n",
    "ks['deadline'] = pd.to_datetime(ks.deadline).dt.date\n",
    "\n",
    "# calculate new variable\n",
    "ks['duration'] = (ks.deadline - ks.launched).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='state',y='duration',data=ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = ks[ks.duration<ks.duration.quantile(.95)]\n",
    "sns.boxplot(x='state',y='duration',data=ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simplify `state` to have only binary values that indicate successful and unsuccessful campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks['state_simple'] = ks.state.apply(lambda state: 1 if state=='successful' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.state_simple.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also simplify 'currency' to binary values for USD or not USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks['USD?'] = ks.currency.apply(lambda curr: 1 if curr=='USD' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.groupby('state_simple')['USD?'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create dummy variables for `category`, `main_category`, and `currency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.get_dummies(ks.category, drop_first=True)\n",
    "main_category = pd.get_dummies(ks.main_category, drop_first=True)\n",
    "currency = pd.get_dummies(ks.currency, drop_first=True)\n",
    "\n",
    "# put all categorical variables in one df\n",
    "cat_var = pd.concat([category,main_category,currency],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4. implement classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to implement different classification models. Let's first use a KNeighbors model and try feeding the model everything. Note: Because the dataframe is really big, I first shrunk it down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sample = ks[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ks_sample[['duration','backers','usd_goal_real']].join(cat_var)\n",
    "y = ks_sample.state_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it again with only `duration`, `backers`, and `usd_goal_real`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ks_sample[['duration','backers','usd_goal_real']]\n",
    "y = ks_sample.state_simple\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with `duration`, `backers`, `main_category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ks_sample[['duration','backers']].join(main_category)\n",
    "y = ks_sample.state_simple\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with all the categories but using `USD?` instead of `currency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ks_sample[['duration','backers','usd_goal_real','USD?']].join(pd.concat([main_category,category],axis=1))\n",
    "y = ks_sample.state_simple\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try one last time with `backers` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ks_sample[['backers']]\n",
    "y = ks_sample.state_simple\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like its between the first and second model. Let's continue optimizing the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### step 5. optimize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ks_sample[['duration','backers','usd_goal_real']].join(cat_var)\n",
    "y = ks_sample.state_simple\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement a grid search to optimize the number of neighbors and use a pipe to first implement a `StandardScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(),KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kneighborsclassifier__n_neighbors': list(range(3, 10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid=params, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = grid.best_estimator_\n",
    "\n",
    "best.fit(X_train, y_train)\n",
    "y_pred = best.predict(X_test)\n",
    "\n",
    "print('accuracy score:',accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ironically a grid search did not actually improve the model. In this instance, the grid found that n_neighbors=5 is the most optimal. Given that that was the same value I had used above, it seems like the `StandardScaler()` is the main reason for a slightly lower accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 6. compare to a dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "print('accuracy score:',accuracy_score(y_test,dummy_pred))\n",
    "print(classification_report(y_test,dummy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least our model does much better than a dummy classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 7. try a logistic regressor instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipe\n",
    "pipe = make_pipeline(StandardScaler(), PolynomialFeatures(), LogisticRegression())\n",
    "\n",
    "# set parameters\n",
    "params = {'polynomialfeatures__degree': list(range(2, 10))}\n",
    "\n",
    "# perform grid search\n",
    "grid = GridSearchCV(pipe, param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best = grid.best_estimator_\n",
    "best.fit(X_train, y_train)\n",
    "best_pred = best.predict(X_test)\n",
    "\n",
    "print('accuracy score:',accuracy_score(y_test,best_pred))\n",
    "print(classification_report(y_test,best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
